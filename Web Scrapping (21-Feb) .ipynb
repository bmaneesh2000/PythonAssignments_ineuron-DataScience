{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1\n",
    "\n",
    "\"\"\" Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data. \"\"\"\n",
    "\n",
    "#Answers\n",
    "\n",
    "\n",
    "Web Scrapping : Web scraping is an automatic method to obtain large amounts of data from websites. \n",
    "Most of this data is unstructured data in an HTML format which is then converted into structured data in a spreadsheet or a database so that it can be used in various applications. There are many different ways to perform web scraping to obtain data from websites. \n",
    "These include using online services, particular APIs or even creating your code for web scraping from scratch. \n",
    "Many large websites, like Google, Twitter, Facebook, StackOverflow, etc. have APIs that allow you to access their data in a structured format. \n",
    "\n",
    "Dataset Obtained can be used to analyse and determine buisness driven decisions.\n",
    "\n",
    "Web Scrapping is used for : Price Monitoring, Market Research , News Monitoring, Sentiment Analysis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2\n",
    "\n",
    "\"\"\" Q2. What are the different methods used for Web Scraping? \"\"\"\n",
    "\n",
    "#Answers\n",
    "\n",
    "We can use various menthods to scrap the web \n",
    "\n",
    "HTML Parsing\n",
    "HTML parsing involves the use of JavaScript to target a linear or nested HTML page. It is a powerful and fast method for extracting text and links (e.g. a nested link or email address), scraping screens and pulling resources.\n",
    "\n",
    "DOM Parsing\n",
    "The Document Object Model (DOM) defines the structure, style and content of an XML file. Scrapers typically use a DOM parser to view the structure of web pages in depth. DOM parsers can be used to access the nodes that contain information and scrape the web page with tools like XPath. For dynamically generated content, scrapers can embed web browsers like Firefox and Internet Explorer to extract whole web pages (or parts of them).\n",
    "\n",
    "Vertical Aggregation\n",
    "Companies that use extensive computing power can create vertical aggregation platforms to target particular verticals. These are data harvesting platforms that can be run on the cloud and are used to automatically generate and monitor bots for certain verticals with minimal human intervention. Bots are generated according to the information required to each vertical, and their efficiency is determined by the quality of data they extract.\n",
    "\n",
    "XPath\n",
    "XPath is short for XML Path Language, which is a query language for XML documents. XML documents have tree-like structures, so scrapers can use XPath to navigate through them by selecting nodes according to various parameters. A scraper may combine DOM parsing with XPath to extract whole web pages and publish them on a destination site.\n",
    "\n",
    "Google Sheets\n",
    "Google Sheets is a popular tool for data scraping. Scarpers can use the IMPORTXML function in Sheets to scrape from a website, which is useful if they want to extract a specific pattern or data from the website. This command also makes it possible to check if a website can be scraped or is protected."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3\n",
    "\n",
    "\"\"\" Q3. What is Beautiful Soup? Why is it used? \"\"\"\n",
    "\n",
    "#Answer\n",
    "\n",
    "Beautiful Soup is a Python package for parsing HTML and XML documents. It creates a parse tree for parsed pages that can be used to extract data from HTML, which is useful for web scraping. It is used to parse through the http request objest and parse through the html and to extract data with respect to its tags and beautify and make the document more readable."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#4\n",
    "\n",
    "\"\"\" Q4. Why is flask used in this Web Scraping project? \"\"\"\n",
    "\n",
    "#Answer\n",
    "\n",
    "Flask is used to create an API to initate the request to download the html source document that can be scraped and analysed on the server end, the results can then be used to display back on the clind side frontend by passing them through another API."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#5\n",
    "\n",
    "\"\"\" Q5. Write the names of AWS services used in this project. Also, explain the use of each service. \"\"\"\n",
    "\n",
    "#Answer\n",
    "\n",
    "#CODE PIPELINE\n",
    "#BEAN STACK\n",
    "\n",
    "AWS CodePipeline is a continuous delivery service you can use to model, visualize, and automate the steps required to release your software. You can quickly model and configure the different stages of a software release process. CodePipeline automates the steps required to release your software changes continuously.\n",
    "\n",
    "AWS Elastic Beanstalk is an orchestration service offered by Amazon Web Services for deploying applications which orchestrates various AWS services, including EC2, S3, Simple Notification Service (SNS), CloudWatch, autoscaling, and Elastic Load Balancers with Elastic Beanstalk, you can quickly deploy and manage applications in the AWS Cloud without having to learn about the infrastructure that runs those applications. Elastic Beanstalk reduces management complexity without restricting choice or control. You simply upload your application, and Elastic Beanstalk automatically handles the details of capacity provisioning, load balancing, scaling, and application health monitoring.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
